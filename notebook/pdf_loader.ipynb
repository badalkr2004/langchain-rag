{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73203db",
   "metadata": {},
   "source": [
    "### RAG Pipelines - Data Ingestion to Vector DB pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3f6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c63d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 PDF files to process\n",
      "\n",
      "Processing: attention.pdf\n",
      "✔️ Loaded 1 pages\n",
      "\n",
      "Processing: embeddings.pdf\n",
      "✔️ Loaded 1 pages\n",
      "\n",
      "Processing: objectdetection.pdf\n",
      "✔️ Loaded 1 pages\n",
      "\n",
      " Total Documents Loaded: 3\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdfs inside the directory\n",
    "\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all pdf files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    ## find all pdf files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            # add the source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata[\"source_file\"] = pdf_file.name\n",
    "                doc.metadata[\"file_type\"] = \"pdf\"\n",
    "\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"✔️ Loaded {len(documents)} pages\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e} pages\")\n",
    "\n",
    "    print(f\"\\n Total Documents Loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "\n",
    "## process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "147bdd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-07T13:18:48+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-07T13:18:48+00:00', 'subject': '(unspecified)', 'title': 'Attention in Machine Learning', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Attention in Machine Learning\\nAttention in Machine Learning is a concept that allows models to focus on the most\\nrelevant parts of the input data when making predictions. It was first introduced in\\nthe field of Natural Language Processing (NLP) and has become a key idea behind\\nmany modern AI models such as Transformers, BERT, and GPT.\\nIn traditional neural networks, all input data is treated equally, which can make it\\ndifficult for models to capture long-term dependencies. Attention solves this by\\nassigning different “weights” to different parts of the input, meaning the model can\\ndecide which words, pixels, or features are most important for the current task.\\nThe mechanism works by computing a score for each input element based on its\\nrelevance to the output being generated. These scores are then converted into\\nprobabilities using a softmax function. The model uses these probabilities to focus\\nmore on important elements while ignoring less relevant ones.\\nThere are different types of attention mechanisms, including: \\x7f Additive Attention –\\ncompares the query and key using a feed-forward network. \\x7f Dot-Product\\n(Multiplicative) Attention – uses a dot product to measure similarity. \\x7f Self-Attention\\n– allows a sequence to look at itself to capture relationships between its elements.\\nThis is the foundation of the Transformer model.\\nIn summary, Attention helps models understand context better by dynamically\\nfocusing on relevant information. It has revolutionized how machines process\\nlanguage, images, and even videos, making it one of the most powerful ideas in\\nmodern Artificial Intelligence.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-07T13:20:25+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-07T13:20:25+00:00', 'subject': '(unspecified)', 'title': 'Embeddings in Machine Learning', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\embeddings.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Embeddings in Machine Learning\\nEmbeddings in Machine Learning are a way to represent complex data (like words,\\nimages, or items) as numerical vectors in a continuous space. This transformation\\nallows algorithms to understand similarities and relationships between data points\\nmore effectively.\\nMost machine learning models work with numbers, not raw text or images.\\nEmbeddings solve this problem by converting high-dimensional or symbolic data\\ninto lower-dimensional numeric form. This helps models learn patterns, context,\\nand relationships between data points.\\nAn embedding maps each item (for example, a word) to a vector of real numbers.\\nThe goal is for similar items to have vectors that are close together in the\\nembedding space. For example, in a word embedding model, the vectors for “king”\\nand “queen” will be close because they share similar meanings.\\nCommon types of embeddings include: \\x7f Word Embeddings – Represent words as\\nvectors (e.g., Word2Vec, GloVe, FastText). \\x7f Sentence or Document Embeddings\\n– Represent larger text units (e.g., Sentence-BERT, Universal Sentence Encoder).\\n\\x7f Image Embeddings – Represent visual data (used in computer vision tasks). \\x7f\\nGraph Embeddings – Represent nodes in graphs while preserving relationships.\\nEmbeddings are widely used in applications like recommendation systems, search\\nengines, natural language processing, and image recognition. They allow models\\nto understand semantic meaning, similarity, and context beyond simple keyword\\nmatching.\\nIn summary, embeddings are the foundation of many modern AI systems. They\\nenable machines to represent and reason about data in a meaningful way, bridging\\nthe gap between raw information and intelligent understanding.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-07T13:21:17+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-07T13:21:17+00:00', 'subject': '(unspecified)', 'title': 'Object Detection in Machine Learning', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\objectdetection.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Object Detection in Machine Learning\\nObject Detection is a computer vision technique that allows machines to identify\\nand locate multiple objects within an image or video. It not only tells what objects\\nare present but also where they are located using bounding boxes.\\nUnlike simple image classification, which only identifies the category of an image,\\nobject detection provides spatial information by drawing boxes around each\\ndetected object. This makes it useful for real-world applications like autonomous\\nvehicles, surveillance, and medical imaging.\\nObject detection models usually work in two steps: first, they extract important\\nfeatures from the image, and then they classify and localize objects. Modern deep\\nlearning models use convolutional neural networks (CNNs) to perform both steps\\nefficiently.\\nPopular object detection architectures include: \\x7f R-CNN and Fast R-CNN – Use\\nregion proposals followed by CNN-based classification. \\x7f YOLO (You Only Look\\nOnce) – Performs detection in a single pass, making it very fast. \\x7f SSD (Single\\nShot MultiBox Detector) – Balances speed and accuracy using multiple feature\\nmaps. \\x7f Faster R-CNN – Combines region proposal and detection into one network\\nfor higher efficiency.\\nApplications of object detection include: \\x7f Self-driving cars (detecting pedestrians,\\ntraffic signs, vehicles) \\x7f Security systems (face and motion detection) \\x7f Healthcare\\n(detecting tumors or medical anomalies) \\x7f Retail (inventory monitoring and shelf\\nanalysis) \\x7f Robotics (object localization and manipulation)\\nIn summary, Object Detection combines the power of image classification and\\nlocalization, enabling machines to visually understand and interact with their\\nenvironment. It is a cornerstone technology in computer vision and continues to\\nevolve with more efficient and accurate models.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8787f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text Splitting get into chunks\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\" \"Split docuemnts into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"\\nSplit {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    ## show example of chunk\n",
    "    if split_docs:\n",
    "        print(\"\\nExample chunk:\")\n",
    "        print(f\"Content: \\n{split_docs[0].page_content}\\n---\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3c1c59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split 3 documents into 7 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: \n",
      "Attention in Machine Learning\n",
      "Attention in Machine Learning is a concept that allows models to focus on the most\n",
      "relevant parts of the input data when making predictions. It was first introduced in\n",
      "the field of Natural Language Processing (NLP) and has become a key idea behind\n",
      "many modern AI models such as Transformers, BERT, and GPT.\n",
      "In traditional neural networks, all input data is treated equally, which can make it\n",
      "difficult for models to capture long-term dependencies. Attention solves this by\n",
      "assigning different “weights” to different parts of the input, meaning the model can\n",
      "decide which words, pixels, or features are most important for the current task.\n",
      "The mechanism works by computing a score for each input element based on its\n",
      "relevance to the output being generated. These scores are then converted into\n",
      "probabilities using a softmax function. The model uses these probabilities to focus\n",
      "more on important elements while ignoring less relevant ones.\n",
      "---\n",
      "Metadata: {'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-07T13:18:48+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-07T13:18:48+00:00', 'subject': '(unspecified)', 'title': 'Attention in Machine Learning', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'attention.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a8528",
   "metadata": {},
   "source": [
    "### Embedding and Vector Store DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc5fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GENAi\\Langchain_RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc42b265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GENAi\\Langchain_RAG\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\badal\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1e508736d50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using Sentence Transformer\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialzes the embedding manager\n",
    "\n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the sentence Tranformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(\n",
    "                f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "\n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "\n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not found\")\n",
    "\n",
    "        print(f\"Generating embeddings for {len(texts) } texts...\")\n",
    "        embeddings = self.model.encode(texts,show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12158e1b",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86f89ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store initialzed. Colleciton: pdf_documents\n",
      "Existing documents in collection: 7\n"
     ]
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a chromaDB vector Store\"\"\"\n",
    "\n",
    "    def __init__(self,collection_name:str = \"pdf_documents\",persist_directory:str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store \n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store \n",
    "        \"\"\"\n",
    "\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChormaDB client and connection\"\"\"\n",
    "        try:\n",
    "            # create persistent ChromaDb client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create Collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\":\"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "\n",
    "            print(f\"Vector Store initialzed. Colleciton: {self.collection.name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def add_documents(self,documents: List[Any], embeddings:np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "\n",
    "        Args:\n",
    "            docuements: List of langchain documents\n",
    "            embeddings: Corresponding embeddings for the documents \n",
    "        \"\"\"\n",
    "\n",
    "        if(len(documents) != len(embeddings)):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "\n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        ## prepare data for chroma db\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embedding_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents,embeddings)):\n",
    "            # Generate unique id\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_i\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "\n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index']= i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # Embedding\n",
    "            embedding_list.append(embedding.tolist())\n",
    "\n",
    "        # Add Coolection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings =embedding_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vector_store = VectorStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "136001f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 7 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (7, 384)\n",
      "Adding 7 documents to vector store...\n",
      "Successfully added 7 documents to vector store\n",
      "Total documents in collection: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Conver the text to embeddings and add to vector store\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "## store in the vector database\n",
    "vector_store.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfd9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
